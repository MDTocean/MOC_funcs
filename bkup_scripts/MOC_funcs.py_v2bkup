import matplotlib.pyplot as plt
from matplotlib import gridspec
# import om4labs
import xarray as xr
import numpy as np
import sectionate
from numba import njit
from glob import glob
import momlevel
from cmip_basins.basins import generate_basin_codes
from xhistogram.xarray import histogram
import sys

def MOC_xsec_nodes_online(
    dir_base,
    section_node_lons,
    section_node_lats,
    file_str_identifier,
    dir_vars="gfdl.ncrc4-intel18-prod-openmp/pp/ocean_annual_rho2/ts/annual/10yr/",
    dir_grid="gfdl.ncrc4-intel18-prod-openmp/pp/ocean_annual_rho2/ocean_annual_rho2.static.nc",
    z_layer_var="rho2_l",
    z_inter_var="rho2_i",
    u_transport_var="umo",
    v_transport_var="vmo",
    time_limits=[],
    x_hpoint_1Dvar="xh",
    x_qpoint_1Dvar="xq",
    y_hpoint_1Dvar="yh",
    y_qpoint_1Dvar="yq",
    time_var="time",
    lons_tpoint="geolon",
    lats_tpoint="geolat",
    lons_cpoint="geolon_c",
    lats_cpoint="geolat_c",
    plot_flag=True,
    decode_times_flag=True,
):
    """Calculate MOC along the specified cross section  (from section_node points). 
    Defaults are set to calculate density-space AMOC from online density-space transports, 
    but the directory and variable names can be changed to select any other variable. 
    
    Args:
        dir_base (string): base directory of the simulation to be used e.g. "/archive/Raphael.Dussin/FMS2019.01.03_devgfdl_20210706/CM4_piControl_c192_OM4p125_v6_alt3/"
        section_node_lons (vector): 1D vector of longitude nodes that (together with section_node_lats) define a cross section. E.g.: [60.3000, 58.8600, 58.0500, 58.0000, 56.5000]
        section_node_lats (vector): 1D vector of latitude nodes that define the cross section. For use in Raphael Dussin's sectionate tool, which finds all grid cell locations along straight lines between each lon/lat node. E.g [-44.9000, -30.5400, -28.0000, -14.7000, -5.9300]
        file_str_identifier (string): string that identifies a particular output file or set of output files. E.g. ".0196*", which will identify all strings containing '.0196'
        dir_vars (string): subdirectory containing the depth-space output files. 
        dir_grid (string): subdirectory cotaining the grid info file
        z_layer_var (string): variable name for the vertical coordinate at the grid centre
        z_inter_var (string): variable name for the vertical coordinate at the grid interface
        u_transport_var (string): variable name for the zonal transport
        v_transport_var (string): variable name for the meridional transport
        time_limits (vector): a 2-element vector of the type [time_start,time_limit], using the same units as in the data, that allows the data to be limited within these time margins 
        x_hpoint_1Dvar (string) etc: coordinate names of the 1D lon and lat q and h points
        lons_tpoint (string) etc: variable names for the 2D lon and lat grid at the grid centre
        lons_cpoint (string) etc: variable names for the 2D lon and lat grid at the grid corner
        time_var (string): coordinate name of the time dimension
        plot_flag (logical): if True then the routine will make some basic plots
        decode_times_flag (logical): use metadata to convert time to a date

    output:
        dsT (xarray dataset):  output from Raphael Dussin's sectionate tool, containing transport and grid information along the specified cross-section
        MOC_mean (xarray dataset): MOC streamfunction calculated along the specified cross section
        MOC_ts (xarray dataset): timeseries of maximum MOC along the specified cross section

    """
    
    umo_vars_str=dir_base+dir_vars+"*"+file_str_identifier+"*."+u_transport_var+".nc"
    vmo_vars_str=dir_base+dir_vars+"*"+file_str_identifier+"*."+v_transport_var+".nc"
    files_timestep=glob(f"{umo_vars_str}")
    files_timestep+=glob(f"{vmo_vars_str}")
    
    ds = xr.open_mfdataset(files_timestep, decode_times=decode_times_flag, chunks={'xh' : 100, 'xq' : 100, 'yh' : 100, 'yq' : 100})
    grid=xr.open_dataset(dir_base+dir_grid)
    
    ### If there are not the same number of dimensions of yq and yh, cut off the extra dimension:
    if len(ds[y_qpoint_1Dvar])==len(ds[y_hpoint_1Dvar])+1:
        ds = ds.isel( { y_qpoint_1Dvar: slice(1,len(ds[y_qpoint_1Dvar])) } )
        grid = grid.isel( { y_qpoint_1Dvar: slice(1,len(ds[y_qpoint_1Dvar])) } )
    elif len(ds[y_qpoint_1Dvar])==len(ds[y_hpoint_1Dvar]):
        'this is fine'
    else:
        raise Exception("yq must be more positive than yh or be 1 element larger than yh")
    if len(ds[x_qpoint_1Dvar])==len(ds[x_hpoint_1Dvar])+1:
        ds = ds.isel( { x_qpoint_1Dvar: slice(1,len(ds[x_qpoint_1Dvar])) } )
        grid = grid.isel( { x_qpoint_1Dvar: slice(1,len(ds[x_qpoint_1Dvar])) } )
    elif len(ds[x_qpoint_1Dvar])==len(ds[x_hpoint_1Dvar]):
        'this is fine'
    else:
        raise Exception("xq must be more positive than xh or be 1 element larger than xh")

    ### If the 1D coordinate names are not xh,xq, etc, then rename them to x_hpoint_1Dvar, x_qpoint_1Dvar etc
    if y_hpoint_1Dvar != "yh":
        ds = ds.rename({y_hpoint_1Dvar: 'yh'})
        grid = grid.rename({y_hpoint_1Dvar: 'yh'})
    if y_qpoint_1Dvar != "yq":
        ds = ds.rename({y_qpoint_1Dvar: 'yq'})
        grid = grid.rename({y_qpoint_1Dvar: 'yq'})
    if x_hpoint_1Dvar != "xh":
        ds = ds.rename({x_hpoint_1Dvar: 'xh'})
        grid = grid.rename({x_hpoint_1Dvar: 'xh'})
    if x_qpoint_1Dvar != "xq":
        ds = ds.rename({x_qpoint_1Dvar: 'xq'})
        grid = grid.rename({x_qpoint_1Dvar: 'xq'})
    if time_var != "time":
        ds = ds.rename({time_var: 'time'})
        grid = grid.rename({time_var: 'time'})
    
    ### Reduce xarray data domain to fit around chosen section coordinates
    lat_range_min=np.abs(ds.yh-(min(section_node_lats)-1)).argmin()
    lat_range_max=np.abs(ds.yh-(max(section_node_lats)+1)).argmin()
    lon_range_min=np.abs(ds.xh-(min(section_node_lons)-1)).argmin()
    lon_range_max=np.abs(ds.xh-(max(section_node_lons)+10)).argmin()
    if np.any(time_limits):
        ds_subpolar = ds.sel(yq=slice(ds.yq[lat_range_min],ds.yq[lat_range_max]),xh=slice(ds.xh[lon_range_min],ds.xh[lon_range_max]),yh=slice(ds.yh[lat_range_min],ds.yh[lat_range_max]),xq=slice(ds.xq[lon_range_min],ds.xq[lon_range_max]),time=slice(time_limits[0],time_limits[1]))
    else: 
        ds_subpolar = ds.sel(yq=slice(ds.yq[lat_range_min],ds.yq[lat_range_max]),xh=slice(ds.xh[lon_range_min],ds.xh[lon_range_max]),yh=slice(ds.yh[lat_range_min],ds.yh[lat_range_max]),xq=slice(ds.xq[lon_range_min],ds.xq[lon_range_max]))
    grid_subpolar = grid.sel(yq=slice(ds.yq[lat_range_min],ds.yq[lat_range_max]),xh=slice(ds.xh[lon_range_min],ds.xh[lon_range_max]),yh=slice(ds.yh[lat_range_min],ds.yh[lat_range_max]),xq=slice(ds.xq[lon_range_min],ds.xq[lon_range_max]))
    	
    ### Run Raf's sectionate tool to extract T,S and V along chosen section coordinates
    isec, jsec, xsec, ysec = sectionate.create_section_composite(grid_subpolar['geolon_c'],
                                                                 grid_subpolar['geolat_c'],
                                                                 section_node_lons,
                                                                 section_node_lats)
    
    [corner_offset1,corner_offset2]=sectionate.find_offset_center_corner(grid_subpolar[lons_tpoint], grid_subpolar[lats_tpoint], grid_subpolar[lons_cpoint], grid_subpolar[lats_cpoint])
    
    dsT = sectionate.MOM6_normal_transport(ds_subpolar, isec, jsec,utr=u_transport_var,vtr=v_transport_var,layer=z_layer_var,interface=z_inter_var,offset_center_x=corner_offset1,offset_center_y=corner_offset2,old_algo=True)
    transp_vals=dsT.uvnormal
    
    earth_radius=6371000  # in km
    section_gridwidth=earth_radius*sectionate.distance_on_unit_sphere(ysec[0:-1],xsec[0:-1],ysec[1:],xsec[1:])
    
    MOC_mean=dsT.uvnormal.mean(dim=time_var).sum(dim='sect',skipna=True).cumsum(dim=z_layer_var)/1030/1e6
    MOC_ts=dsT.uvnormal.sum(dim='sect',skipna=True).cumsum(dim=z_layer_var).max(dim=z_layer_var)/1030/1e6

    if plot_flag==1:
        plt.figure(figsize=(8,6)),MOC_mean.plot(y=z_layer_var,ylim=[1033,1037.5])
        plt.figure(figsize=(8,6)),MOC_ts.plot()
        
    return dsT, MOC_mean, MOC_ts, xsec, ysec

def MOC_basin_latrange_online(
    dir_base,
    file_str_identifier,
    dir_vars="gfdl.ncrc4-intel18-prod-openmp/pp/ocean_annual_rho2/ts/annual/10yr/",
    dir_grid="gfdl.ncrc4-intel18-prod-openmp/pp/ocean_annual_rho2/ocean_annual_rho2.static.nc",
    lat_range=[],
    lon_range=[],
    depth_range=[],
    basin_list=[],
    z_layer_var="rho2_l",
    z_inter_var="rho2_i",
    v_transport_var="vmo",
    time_limits=[],
    x_hpoint_1Dvar="xh",
    x_qpoint_1Dvar="xq",
    y_hpoint_1Dvar="yh",
    y_qpoint_1Dvar="yq",
    time_var="time",
    lons_tpoint="geolon",
    lats_tpoint="geolat",
    lons_cpoint="geolon_c",
    lats_cpoint="geolat_c",
    decode_times_flag=True,
):
    """Calculate MOC over the given range of latitudes (according to lat_range variable). 
    Defaults are set to calculate density-space AMOC from online density-space transports, 
    but the directory and variable names can be changed to select any e.g. offline variables. 
    
    Additional Args:
        lat_range (list): 1-element, or 2-element vector (i.e. [start_lat,end_lat]). Can be left empty (i.e. global). Select the lat, and not the index. Must be in square brackets
        lon_range (list): 1-element, or 2-element vector (i.e. [start_lon,end_lon]). Can be left empty (i.e. global). Select the lon, and not the index. Must be in square brackets
        depth_range (list): 1-element, or 2-element vector (i.e. [start_depth,end_depth]).  Can be left emptySelect the depth (or density!), and not the index. Must be in square brackets
        basin_list (list): list of basins according to John Krasting's generate_basin_codes, e.g. [2,3,5] is [Atl,Pac,Ind]. 1=SO; 4=Arc; 6=Med; 7=Black Sea(?); 8=Hud Bay(?): 9=Balt. Sea(?); 10=Red Sea(?). Must be in square brackets

    output:
        ds (xarray dataset):  dataset of meridional transport for the specific basin(s) (if any) and specified ranges
        moc (xarray dataset): MOC streamfunction calculated for the specific basin(s) (if any) and specified ranges
        vmo_zonmean (xarray dataset): zonally-integrated meridional transports across the specific basin(s) (if any) and specified ranges

    """
    
    vmo_vars_str=dir_base+dir_vars+"*"+file_str_identifier+"*."+v_transport_var+".nc"
    files_timestep=glob(f"{vmo_vars_str}")
    
    ds = xr.open_mfdataset(files_timestep, decode_times=decode_times_flag, chunks={'xh' : 100, 'xq' : 100, 'yh' : 100, 'yq' : 100})
    grid=xr.open_dataset(dir_base+dir_grid)
    
    ### Cut off the final yq index, since the grid file has a problem there in CM4_hires
    ds = ds.isel( { y_qpoint_1Dvar: slice(0,-1) } )
    grid = grid.isel( { y_qpoint_1Dvar: slice(0,-1) } )
    
    ### If the 1D coordinate names are not xh,xq, etc, then rename them to x_hpoint_1Dvar, x_qpoint_1Dvar etc
    if y_hpoint_1Dvar != "yh":
        ds = ds.rename({y_hpoint_1Dvar: 'yh'})
        grid = grid.rename({y_hpoint_1Dvar: 'yh'})
    if y_qpoint_1Dvar != "yq":
        ds = ds.rename({y_qpoint_1Dvar: 'yq'})
        grid = grid.rename({y_qpoint_1Dvar: 'yq'})
    if x_hpoint_1Dvar != "xh":
        ds = ds.rename({x_hpoint_1Dvar: 'xh'})
        grid = grid.rename({x_hpoint_1Dvar: 'xh'})
    if x_qpoint_1Dvar != "xq":
        ds = ds.rename({x_qpoint_1Dvar: 'xq'})
        grid = grid.rename({x_qpoint_1Dvar: 'xq'})
    if time_var != "time":
        ds = ds.rename({time_var: 'time'})
        grid = grid.rename({time_var: 'time'})    

    if basin_list:
        basincodes_v = generate_basin_codes(grid, lon="geolon_v", lat="geolat_v", mask="wet_v")
    
    if len(lat_range)==2:
        ds=ds.sel(yq=slice(lat_range[0],lat_range[1]))
        grid=grid.sel(yq=slice(lat_range[0],lat_range[1]))
        if basin_list: basincodes_v=basincodes_v.sel(yq=slice(lat_range[0],lat_range[1]))
    elif len(lat_range)==1:
        ds=ds.sel(yq=lat_range,method='nearest')
        grid=grid.sel(yq=lat_range,method='nearest')
        if basin_list: basincodes_v=basincodes_v.sel(yq=lat_range,method='nearest')
    elif len(lat_range)>2:
        raise Exception("lat_range can have a length of zero (i.e. empty), or 1 or 2 elements")
    
    if len(lon_range)==2:
        ds=ds.sel(xh=slice(lon_range[0],lon_range[1]))
        grid=grid.sel(xh=slice(lon_range[0],lon_range[1]))
        if basin_list: basincodes_v=basincodes_v.sel(xh=slice(lon_range[0],lon_range[1]))
    elif len(lon_range)==0: 'then do nothing'
    else:
        raise Exception("lon_range must be empty or have 2 elements")
        
    if len(depth_range)==2:
        ds=ds.sel(z_l=slice(depth_range[0],depth_range[1]))
    elif len(depth_range)==0: 'then do nothing'
    else:
        raise Exception("depth_range must be empty or have 2 elements")
    
    num_basins=len(basin_list)
    if num_basins==0:
        'nothing needed'
    elif num_basins==1:
        ds=ds.where(basincodes_v==basin_list)
    elif num_basins==2:
        ds=ds.where((basincodes_v==basin_list[0]) | (basincodes_v==basin_list[1]))
    elif num_basins==3:
        ds=ds.where((basincodes_v==basin_list[0]) | (basincodes_v==basin_list[1]) | (basincodes_v==basin_list[2]))
    elif num_basins==4:
        ds=ds.where((basincodes_v==basin_list[0]) | (basincodes_v==basin_list[1]) | (basincodes_v==basin_list[2]) | (basincodes_v==basin_list[3]))
    else:
        raise Exception("I haven't coded in for more basins than this. You'll have to add in another line to elif list")
    
    vmo_zonmean=ds[v_transport_var].sum(x_hpoint_1Dvar)
    vmo_zonmean=vmo_zonmean/1030/1e6
    moc=vmo_zonmean.cumsum(z_layer_var) 

    return ds, moc, vmo_zonmean

def MOC_basin_latrange_offline(
    dir_base,
    file_str_identifier,
    calc_rho_flag=False,
    nrho=500,
    rholims=[21,28.1],
    ref_pres=0,
    dir_vars="gfdl.ncrc4-intel18-prod-openmp/pp/ocean_month_z/ts/monthly/5yr/",
    dir_grid="gfdl.ncrc4-intel18-prod-openmp/pp/ocean_month_z/ocean_month_z.static.nc",
    lat_range=[],
    lon_range=[],
    depth_range=[],
    basin_list=[],
    z_layer_var="z_l",
    z_inter_var="z_i",
    v_transport_var="vmo",
    theta_var="thetao",
    salt_var="so",
    rho_var="rhopot0",
    time_limits=[],
    x_hpoint_1Dvar="xh",
    x_qpoint_1Dvar="xq",
    y_hpoint_1Dvar="yh",
    y_qpoint_1Dvar="yq",
    time_var="time",
    lons_tpoint="geolon",
    lats_tpoint="geolat",
    lons_cpoint="geolon_c",
    lats_cpoint="geolat_c",
    decode_times_flag=True,
    dmgetout=False,
    zarr_dir='',
):
    
    vmo_vars_str=dir_base+dir_vars+"*"+file_str_identifier+"*."+v_transport_var+".nc"
    files_timestep=glob(f"{vmo_vars_str}")
    if dmgetout: 
        print(f'dmget commands:')
        print(f"{'dmget '+vmo_vars_str+' &'}")
    if calc_rho_flag==False:
        rho_vars_str=dir_base+dir_vars+"*"+file_str_identifier+"*."+rho_var+".nc"
        files_timestep+=glob(f"{rho_vars_str}")
        if dmgetout: 
            print(f"{'dmget '+rho_vars_str+' &'}")
            sys.exit("first run dmget command(s)")
    elif calc_rho_flag == True:
        theta_vars_str=dir_base+dir_vars+"*"+file_str_identifier+"*."+theta_var+".nc"
        salt_vars_str=dir_base+dir_vars+"*"+file_str_identifier+"*."+salt_var+".nc"
        files_timestep+=glob(f"{theta_vars_str}")
        files_timestep+=glob(f"{salt_vars_str}")
        if dmgetout: 
            print(f"{'dmget '+theta_vars_str+' &'}")
            print(f"{'dmget '+salt_vars_str+' &'}")
            sys.exit("first run dmget command(s) listed above")
    
    ds = xr.open_mfdataset(files_timestep, decode_times=decode_times_flag, chunks={'xh' : 100, 'yh' : 100, 'yq' : 100})
    grid=xr.open_dataset(dir_base+dir_grid)
    
    ## If there are not the same number of dimensions of yq and yh, cut off the extra dimension:
    if len(ds[y_qpoint_1Dvar])==len(ds[y_hpoint_1Dvar])+1:
        ds = ds.isel( { y_qpoint_1Dvar: slice(1,len(ds[y_qpoint_1Dvar])) } )
        grid = grid.isel( { y_qpoint_1Dvar: slice(1,len(ds[y_qpoint_1Dvar])) } )
    elif len(ds[y_qpoint_1Dvar])==len(ds[y_hpoint_1Dvar]):
        'this is fine'
    else:
        raise Exception("yq must be 1-half-grid more positive (asymmetric) than yh or be 1 element larger than yh (symmetric)")
            
    ### Cut off the final yq index, since the grid file has a problem there in CM4_hires
    ds = ds.isel( { y_qpoint_1Dvar: slice(0,-1),  y_hpoint_1Dvar: slice(0,-1)} )
    grid = grid.isel( { y_qpoint_1Dvar: slice(0,-1),  y_hpoint_1Dvar: slice(0,-1)} )
    
    if basin_list:
        basincodes_v = generate_basin_codes(grid, lon="geolon_v", lat="geolat_v", mask="wet_v")
    
    if len(lat_range)==2:
        ds=ds.sel(yq=slice(lat_range[0],lat_range[1]))
        grid=grid.sel(yq=slice(lat_range[0],lat_range[1]))
        ds=ds.sel(yh=slice(lat_range[0],lat_range[1]))
        grid=grid.sel(yh=slice(lat_range[0],lat_range[1]))        
        if basin_list: basincodes_v=basincodes_v.sel(yq=slice(lat_range[0],lat_range[1]))
    elif len(lat_range)==1:
        nearest_lat=ds.indexes['yq'].get_loc(lat_range[0],method="nearest")
        ds=ds.isel(yq=nearest_lat)
        grid=grid.isel(yq=nearest_lat)
        ds=ds.isel(yh=slice(nearest_lat,nearest_lat+2))
        grid=grid.isel(yh=slice(nearest_lat,nearest_lat+2))
        if basin_list: basincodes_v=basincodes_v.sel(yq=lat_range,method='nearest')
    elif len(lat_range)>2:
        raise Exception("lat_range can have a length of zero (i.e. empty), or 1 or 2 elements")
    
    if len(lon_range)==2:
        ds=ds.sel(xh=slice(lon_range[0],lon_range[1]))
        grid=grid.sel(xh=slice(lon_range[0],lon_range[1]))
        if basin_list: basincodes_v=basincodes_v.sel(xh=slice(lon_range[0],lon_range[1]))
    elif len(lon_range)==0: 'then do nothing'
    else:
        raise Exception("lon_range must be empty or have 2 elements")
        
    if len(depth_range)==2:
        ds=ds.sel(z_l=slice(depth_range[0],depth_range[1]))
    elif len(depth_range)==0: 'then do nothing'
    else:
        raise Exception("depth_range must be empty or have 2 elements")
    
    vmo=ds[v_transport_var]
    if calc_rho_flag:
        so=ds[salt_var].interp(yh=ds[y_qpoint_1Dvar]).drop_vars(y_hpoint_1Dvar)
        thetao=ds[theta_var].interp(yh=ds[y_qpoint_1Dvar]).drop_vars(y_hpoint_1Dvar)
        rhopoto = momlevel.derived.calc_rho(ds[theta_var],ds[salt_var],ref_pres*1e4)
        rhopoto=rhopoto.rename('rhopoto')-1000
    else:
        so=[]
        thetao=[]
        rhopoto=ds[rho_var]-1000
    rhopoto=rhopoto.interp(yh=ds[y_qpoint_1Dvar]).drop_vars(y_hpoint_1Dvar)
    grid=grid.interp(yh=grid['yq'])
    ds=ds.interp(yh=ds['yq'])

    num_basins=len(basin_list)
    if num_basins==0:
        'nothing needed'
    elif num_basins==1:
        ds=ds.where(basincodes_v==basin_list)
        vmo=vmo.where(basincodes_v==basin_list)
        rhopoto=rhopoto.where(basincodes_v==basin_list)
    elif num_basins==2:
        ds=ds.where((basincodes_v==basin_list[0]) | (basincodes_v==basin_list[1]))
        vmo=vmo.where((basincodes_v==basin_list[0]) | (basincodes_v==basin_list[1]))
        rhopoto=rhopoto.where((basincodes_v==basin_list[0]) | (basincodes_v==basin_list[1]))
    elif num_basins==3:
        ds=ds.where((basincodes_v==basin_list[0]) | (basincodes_v==basin_list[1]) | (basincodes_v==basin_list[2]))
        vmo=vmo.where((basincodes_v==basin_list[0]) | (basincodes_v==basin_list[1]) | (basincodes_v==basin_list[2]))
        rhopoto=rhopoto.where((basincodes_v==basin_list[0]) | (basincodes_v==basin_list[1]) | (basincodes_v==basin_list[2]))
    elif num_basins==4:
        ds=ds.where((basincodes_v==basin_list[0]) | (basincodes_v==basin_list[1]) | (basincodes_v==basin_list[2]) | (basincodes_v==basin_list[3]))
        vmo=vmo.where((basincodes_v==basin_list[0]) | (basincodes_v==basin_list[1]) | (basincodes_v==basin_list[2]) | (basincodes_v==basin_list[3]))
        rhopoto=rhopoto.where((basincodes_v==basin_list[0]) | (basincodes_v==basin_list[1]) | (basincodes_v==basin_list[2]) | (basincodes_v==basin_list[3]))
    else:
        raise Exception("I haven't coded in for more basins than this. You'll have to add in another line to elif list")
    
    dens_bins=np.linspace(rholims[0],rholims[1],nrho)
    hist_transpweight=histogram(rhopoto,bins=dens_bins,weights=vmo,dim=['xh'])/1030/1e6
    
    MOCsig_offline=hist_transpweight.mean(dim='time').sum(z_layer_var).cumsum('rhopoto_bin')

    return ds, grid, MOCsig_offline, rhopoto

def MOC_basin_computeMFTMHT(ds,grid,rho,rholims,nrho,rebin_depth=[],rho_dim='rhopoto_bin',z_dim='z_l',dist_var='xh',annual_mean_flag=False,plot_flag=True):
    ### Calculate density- and depth- space MFT and MHT components
    
    Cp=3850 # heat capacity of seawater      

    rho0_ref=rholims[0]+np.arange(0,nrho-1)*((rholims[1]-rholims[0])/nrho); 
    rho0_bounds=rholims[0]-(rho0_ref[1]-rho0_ref[0])/2+np.arange(0,nrho)*((rholims[1]-rholims[0])/nrho); 
    
    ### calculate all tracer SigmaZ matrices 
    ty_z_rho = histogram(rho,bins=[rho0_bounds],weights=ds.vmo.fillna(0.),dim=[dist_var]).squeeze()
    thetao_z_rho = histogram(rho,bins=[rho0_bounds],weights=(ds.thetao*grid.dxCv).fillna(0.),dim=[dist_var]).squeeze()
    so_z_rho = histogram(rho,bins=[rho0_bounds],weights=(ds.so*grid.dxCv).fillna(0.),dim=[dist_var]).squeeze()
    cellarea_z_rho = histogram(rho,bins=[rho0_bounds],weights=(grid.dxCv).fillna(0.),dim=[dist_var]).squeeze()
    thetao_z_rho_mean = thetao_z_rho/cellarea_z_rho  # The mean temperature in each sigma_z cell for OSNAP 
    so_z_rho_mean = so_z_rho/cellarea_z_rho   # The mean salinity in each sigma_z cell for OSNAP 
    
    if len(rebin_depth)>0:
        model_depth=ds[z_dim].isel({ z_dim : slice(1,len(ds[z_dim]))})
        depth_diff=ds[z_dim].diff(z_dim)
        thetao_z_rho=rebin_sigma_z(model_depth.values,depth_diff.values,rebin_depth,thetao_z_rho.values)
        thetao_z_rho=xr.DataArray(data=thetao_z_rho, dims=('time',z_dim,'rhopoto_bin'),coords={'time' : ty_z_rho['time'],z_dim : rebin_depth, 'rhopoto_bin' : ty_z_rho['rhopoto_bin']})
        so_z_rho=rebin_sigma_z(model_depth.values,depth_diff.values,rebin_depth,so_z_rho.values)
        so_z_rho=xr.DataArray(data=so_z_rho, dims=('time',z_dim,'rhopoto_bin'),coords={'time' : ty_z_rho['time'],z_dim : rebin_depth, 'rhopoto_bin' : ty_z_rho['rhopoto_bin']})
        cellarea_z_rho=rebin_sigma_z(model_depth.values,depth_diff.values,rebin_depth,cellarea_z_rho.values)
        cellarea_z_rho=xr.DataArray(data=cellarea_z_rho, dims=('time',z_dim,'rhopoto_bin'),coords={'time' : ty_z_rho['time'],z_dim : rebin_depth, 'rhopoto_bin' : ty_z_rho['rhopoto_bin']})
        ty_z_rho=rebin_sigma_z(model_depth.values,depth_diff.values,rebin_depth,ty_z_rho.values)
        ty_z_rho=xr.DataArray(data=ty_z_rho, dims=('time',z_dim,'rhopoto_bin'),coords={'time' : thetao_z_rho['time'],z_dim : rebin_depth, 'rhopoto_bin' : thetao_z_rho['rhopoto_bin']})

    #### Calculate z- and rho- space zonal means of T,S and V, for use in calculating overturning component of MFT and MHT. 
    S_bar=so_z_rho.fillna(0).sum()/cellarea_z_rho.fillna(0).sum() 
    S_zm_z = so_z_rho.fillna(0).sum(dim=rho_dim)/cellarea_z_rho.fillna(0).sum(dim=rho_dim) 
    S_zm_rho = so_z_rho.fillna(0).sum(dim=z_dim)/cellarea_z_rho.fillna(0).sum(dim=z_dim) # rho-space zonal mean salinity
    theta_zm_z = thetao_z_rho.fillna(0).sum(dim=rho_dim)/cellarea_z_rho.fillna(0).sum(dim=rho_dim) 
    theta_zm_rho = thetao_z_rho.fillna(0).sum(dim=z_dim)/cellarea_z_rho.fillna(0).sum(dim=z_dim) 
    ty_zm_z = ty_z_rho.fillna(0).sum(dim=rho_dim)
    ty_zm_rho = ty_z_rho.fillna(0).sum(dim=z_dim)

    ### calculate MOC MFT
    MFT_MOCrho =- ty_zm_rho*(S_zm_rho-S_bar)/S_bar
    MFT_MOCz =- ty_zm_z*(S_zm_z-S_bar)/S_bar
    MFT_MOCrho_sum = MFT_MOCrho.fillna(0).sum(dim=rho_dim)
    MFT_MOCz_sum = MFT_MOCz.fillna(0).sum(dim=z_dim)
    ### calculate MOC MHT
    MHT_MOCrho = Cp*ty_zm_rho*theta_zm_rho
    
    MHT_MOCz = Cp*ty_zm_z*theta_zm_z
    MHT_MOCrho_sum = MHT_MOCrho.fillna(0).sum(dim=rho_dim)
    MHT_MOCz_sum = MHT_MOCz.fillna(0).sum(dim=z_dim)

    ### calculate the transport*tracer SigmaZ matrices, and calculate (zonal- and total-) integrated MFT 
    Vthetao_z_rho = histogram(rho,bins=[rho0_bounds],weights=(ds.thetao*ds.vmo).fillna(0.),dim=[dist_var]).squeeze()
    Vso_z_rho = -histogram(rho,bins=[rho0_bounds],weights=((ds.so-S_bar)*ds.vmo/S_bar).fillna(0.),dim=[dist_var]).squeeze()
    
    if len(rebin_depth)>0:
        Vthetao_z_rho=rebin_sigma_z(model_depth.values,depth_diff.values,rebin_depth,Vthetao_z_rho.values)
        Vthetao_z_rho=xr.DataArray(data=Vthetao_z_rho, dims=('time',z_dim,'rhopoto_bin'),coords={'time' : ty_z_rho['time'],z_dim : rebin_depth, 'rhopoto_bin' : ty_z_rho['rhopoto_bin']})
        Vso_z_rho=rebin_sigma_z(model_depth.values,depth_diff.values,rebin_depth,Vso_z_rho.values)
        Vso_z_rho=xr.DataArray(data=Vso_z_rho, dims=('time',z_dim,'rhopoto_bin'),coords={'time' : ty_z_rho['time'],z_dim : rebin_depth, 'rhopoto_bin' : ty_z_rho['rhopoto_bin']})

    MFT_zonmean_rho=Vso_z_rho.fillna(0).sum(dim=z_dim)
    MFT_zonmean_z=Vso_z_rho.fillna(0).sum(dim=rho_dim)
    MFT_GYRErho=MFT_zonmean_rho-MFT_MOCrho
    MFT_GYREz=MFT_zonmean_z-MFT_MOCz
    MFT_GYRErho_sum=MFT_GYRErho.fillna(0).sum(dim=rho_dim)
    MFT_GYREz_sum=MFT_GYREz.fillna(0).sum(dim=z_dim)
    MFT_sum=Vso_z_rho.fillna(0.).sum(dim=[z_dim,rho_dim])
    MHT_zonmean_rho=Cp*Vthetao_z_rho.fillna(0).sum(dim=z_dim)
    MHT_zonmean_z=Cp*Vthetao_z_rho.fillna(0).sum(dim=rho_dim)
    MHT_GYRErho=MHT_zonmean_rho-MHT_MOCrho
    MHT_GYREz=MHT_zonmean_z-MHT_MOCz
    MHT_GYRErho_sum=MHT_GYRErho.fillna(0).sum(dim=rho_dim)
    MHT_GYREz_sum=MHT_GYREz.fillna(0).sum(dim=z_dim)
    MHT_sum=Cp*Vthetao_z_rho.fillna(0.).sum(dim=[z_dim,rho_dim])

    MOCrho =ty_z_rho.sum(dim=z_dim).cumsum(dim=rho_dim).max(dim=rho_dim)
    MOCz = ty_z_rho.sum(dim=rho_dim).cumsum(dim=z_dim).max(dim=z_dim)
    
    ### Combine output into single datasets for sigma-, z-, and SigmaZ space
    MOCsig_MHTMFT = xr.Dataset()
    MOCsig_MHTMFT['MOCrho']=MOCrho
    MOCsig_MHTMFT['MHT_zonmean_rho']=MHT_zonmean_rho
    MOCsig_MHTMFT['MHT_sum']=MHT_sum
    MOCsig_MHTMFT['MHT_MOCrho']=MHT_MOCrho
    MOCsig_MHTMFT['MHT_MOCrho_sum']=MHT_MOCrho_sum
    MOCsig_MHTMFT['MHT_GYRErho']=MHT_GYRErho
    MOCsig_MHTMFT['MHT_GYRErho_sum']=MHT_GYRErho_sum
    MOCsig_MHTMFT['MFT_zonmean_rho']=MFT_zonmean_rho
    MOCsig_MHTMFT['MFT_sum']=MFT_sum
    MOCsig_MHTMFT['MFT_MOCrho']=MFT_MOCrho
    MOCsig_MHTMFT['MFT_MOCrho_sum']=MFT_MOCrho_sum
    MOCsig_MHTMFT['MFT_GYRErho']=MFT_GYRErho
    MOCsig_MHTMFT['MFT_GYRErho_sum']=MFT_GYRErho_sum

    MOCz_MHTMFT = xr.Dataset()
    MOCz_MHTMFT['MOCz']=MOCz
    MOCz_MHTMFT['MHT_zonmean_z']=MHT_zonmean_z
    MOCz_MHTMFT['MHT_sum']=MHT_sum
    MOCz_MHTMFT['MHT_MOCz']=MHT_MOCz
    MOCz_MHTMFT['MHT_MOCz_sum']=MHT_MOCz_sum
    MOCz_MHTMFT['MHT_GYREz']=MHT_GYREz
    MOCz_MHTMFT['MHT_GYREz_sum']=MHT_GYREz_sum
    MOCz_MHTMFT['MFT_zonmean_z']=MFT_zonmean_z
    MOCz_MHTMFT['MFT_sum']=MFT_sum
    MOCz_MHTMFT['MFT_MOCz']=MFT_MOCz
    MOCz_MHTMFT['MFT_MOCz_sum']=MFT_MOCz_sum
    MOCz_MHTMFT['MFT_GYREz']=MFT_GYREz
    MOCz_MHTMFT['MFT_GYREz_sum']=MFT_GYREz_sum

    MOCsigz_MHTMFT = xr.Dataset()
    MOCsigz_MHTMFT['Vthetao_z_rho']=Vthetao_z_rho
    MOCsigz_MHTMFT['Vso_z_rho']=Vso_z_rho 
    
    ## temporally rebin the monthly offline timeseries into annual ones
    if annual_mean_flag:
        MOCsig_MHTMFT=MOCsig_MHTMFT.coarsen(time=12).mean()
        MOCz_MHTMFT=MOCz_MHTMFT.coarsen(time=12).mean()
        MOCsigz_MHTMFT=MOCsigz_MHTMFT.coarsen(time=12).mean()
        
    if plot_flag:
        rho0=1030
        fig = plt.figure(figsize=(10,12))
        ax = fig.add_subplot(3,1,1)
        ax.plot(MOCsig_MHTMFT.MOCrho.time,MOCsig_MHTMFT.MOCrho/rho0/1e6)
        ax.set_title('MOC in rho-space')
        ax.set_ylabel('Sv')
        ax = fig.add_subplot(3,1,2)
        ax.plot(MOCsig_MHTMFT.MOCrho.time,(MOCsig_MHTMFT.MHT_sum)/1e15)
        ax.plot(MOCsig_MHTMFT.MOCrho.time,(MOCsig_MHTMFT.MHT_MOCrho_sum)/1e15)
        ax.plot(MOCsig_MHTMFT.MOCrho.time,(MOCsig_MHTMFT.MHT_GYRErho_sum)/1e15)
        ax.set_title('MHT in rho-space')
        ax.set_ylabel('PW')
        ax = fig.add_subplot(3,1,3)
        ax.plot(MOCsig_MHTMFT.MOCrho.time,(MOCsig_MHTMFT.MFT_sum)/rho0/1e6,label='TOTrho')
        ax.plot(MOCsig_MHTMFT.MOCrho.time,(MOCsig_MHTMFT.MFT_MOCrho_sum)/rho0/1e6,label='MOCrho')
        ax.plot(MOCsig_MHTMFT.MOCrho.time,(MOCsig_MHTMFT.MFT_GYRErho_sum)/rho0/1e6,label='GYRErho')
        ax.legend(loc="lower left")
        ax.set_title('MFT in rho-space')
        ax.set_ylabel('Sv')
        ax.set_xlabel('time (months)')
            
    return MOCsig_MHTMFT, MOCz_MHTMFT, MOCsigz_MHTMFT

@njit
def rebin_sigma_z(model_depth,depth_diff,rebin_depth,ty_z_rho):
    ty_z_rho_rebin=np.zeros((np.shape(ty_z_rho)[0],np.shape(rebin_depth)[0],np.shape(ty_z_rho)[2]))
    rebin_depth_index=0;
    for ii in range(0,np.shape(ty_z_rho)[1]-1):
        V=ty_z_rho[:,ii,:]
        depth_range=depth_diff[ii]
        if model_depth[ii]<rebin_depth[rebin_depth_index]:
            ty_z_rho_rebin[:,rebin_depth_index,:]=ty_z_rho_rebin[:,rebin_depth_index,:]+V
        elif model_depth[ii]==rebin_depth[rebin_depth_index]:
            ty_z_rho_rebin[:,rebin_depth_index,:]=ty_z_rho_rebin[:,rebin_depth_index,:]+V
            rebin_depth_index=rebin_depth_index+1
        elif model_depth[ii]>rebin_depth[rebin_depth_index]:
            top_frac=V*(rebin_depth[rebin_depth_index]-model_depth[ii-1])/depth_range
            ty_z_rho_rebin[:,rebin_depth_index,:]=ty_z_rho_rebin[:,rebin_depth_index,:]+top_frac
            if model_depth[ii]<rebin_depth[rebin_depth_index+1]:
                rebin_depth_index=rebin_depth_index+1
                ty_z_rho_rebin[:,rebin_depth_index,:]=ty_z_rho_rebin[:,rebin_depth_index,:]+(V-top_frac)
            else:
                jjj=0
                while model_depth[ii]>rebin_depth[rebin_depth_index+1]:
                    rebin_depth_index=rebin_depth_index+1
                    middle_frac=V*(rebin_depth[rebin_depth_index]-rebin_depth[rebin_depth_index-1])/depth_range
                    ty_z_rho_rebin[:,rebin_depth_index,:]=ty_z_rho_rebin[:,rebin_depth_index,:]+middle_frac
                    jjj=jjj+1
                rebin_depth_index=rebin_depth_index+1
                ty_z_rho_rebin[:,rebin_depth_index,:]=ty_z_rho_rebin[:,rebin_depth_index,:]+(V-top_frac-(jjj*middle_frac))
    return ty_z_rho_rebin

